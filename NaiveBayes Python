import nltk
import csv
from nltk.tokenize import word_tokenize

ifile=open("NaiveBayes_training_dataset_v2.csv", encoding="ISO-8859-1")
reader = csv.DictReader(ifile)
train = []
for row in reader:
    text = row['Statement']
    sentiment = row['Sentiment-Human Interpretation']
    train.append((text,sentiment))
# print(train)

# Step 2
dictionary = set(word.lower() for passage in train for word in word_tokenize(passage[0]))

# Step 3
t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in train]

# Step 4 â the classifier is trained with sample data
classifier = nltk.NaiveBayesClassifier.train(t)

ifile=open("NaiveBayes_test_dataset.csv",encoding = "utf-8")
reader = csv.DictReader(ifile)
ofile = open("NaiveBayes_output.csv",'w+')
writer = csv.DictWriter(ofile, fieldnames=["Statement","Sentiment"])
writer.writeheader()
ofile.close()
for row in reader:
    ofile = open("NaiveBayes_output.csv",'a')
    writer = csv.DictWriter(ofile, fieldnames=["Statement","Sentiment"])
    text= row['Statement']
    test_data_features = {word.lower(): (word in word_tokenize(text.lower())) for word in dictionary}
    print (classifier.classify(test_data_features))
    writer.writerow({"Statement":text,"Sentiment":classifier.classify(test_data_features)})
    ofile.close()
